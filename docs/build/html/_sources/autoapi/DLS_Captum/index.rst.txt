DLS_Captum
==========

.. py:module:: DLS_Captum

.. autoapi-nested-parse::

   ------------
   DeepLiftShap
   ------------

   DeepLiftShap is a feature attribution method.

   For each of the model's output features, feature attribution assigns a value
   to each input feature that is based on its contribution to the model's output.

   The method is implemented through the Captum library.

   For more information on the method, see:
   https://proceedings.neurips.cc/paper_files/paper/2017/file/8a20a8621978632d76c43dfd28b67767-Paper.pdf

   and

   https://captum.ai/api/deep_lift_shap.html



Classes
-------

.. autoapisummary::

   DLS_Captum.DLS


Module Contents
---------------

.. py:class:: DLS(model: type, model_params: dict[str, Any], datamodule: type, path_to_ckpt: str, i_data: str, device: str, seed: int, *, multiply_by_inputs: bool = True)

   Bases: :py:obj:`interpret.featureattr.FeatureAttribution`


   Implement the DeepLiftShap feature attribution method.

   Args:
   ----
       model (type):           The Pytorch model architecture class.

       model_params (dict):    The dictionary needed to intialize model.

       datamodule (type):      The Knowit datamodule for the experiment.

       path_to_ckpt (str):     The path to a trained model's checkpoint file.

       i_data (str):           The user's choice of dataset to perform feature
                               attribution. Choices: 'train', 'valid', 'eval'.

       device (str):           On which hardware device to generate
                               attributions.

       seed (int):             The seed to  be used by Numpy for random
                               sampling of baselines and reproducibility.

       multiply_by
       _inputs (bool):         If True, perform local attributions. If False,
                               perform global attributions. For more inform-
                               ation, see Captum's documentation.



   .. py:method:: generate_baseline_from_data(num_baselines: int) -> torch.Tensor

      Return baseline sample.

      Randomly samples a distribution of baselines from the training data.

      Args:
      ----
          num_baselines (int):    The total number of baselines to sample.

      Returns:
      -------
          (torch.tensor):         A torch tensor of shape (num_baselines,
                                  in_chunk, in_components).




   .. py:method:: interpret(pred_point_id: int | tuple[int, int], num_baselines: int = 1000) -> dict[int | tuple[int, int], dict[str, torch.Tensor]]

      Return attribution matrices and deltas.

      Generates attribution matrices for a single prediction point or a range
      of prediction points (also referred to as explicands).

      NOTE: The output stores the information from a tensor of size

      (out_chunk, out_components, prediction_points, in_chunk, in_components)

      inside a dictionary data structure. For time series data, this can grow
      rapidly, which may therefore obscure model interpretability.

      Args:
      ----
          pred_point_id (int | tuple):
                              The prediction point or range of prediction
                              points that will be used to generate
                              attribution matrices.

          num_baselines (int):
                              Specifies the size of the baseline
                              distribution.

      Returns:
      -------
          results (dict):     For a regression model with output shape
                              (out_chunk, out_components), returns a
                              dictionary as follows:
                                  * Dict Key: a tuple (m, n) with m in range
                                  (out_chunk) and n in range(out_components).
                                  * Dict Element: a torch tensor with shape:
                                          > (prediction_points, in_chunk,
                                          in_components) if pred_point_id is
                                          a tuple.
                                          > (in_chunk, in_components) if
                                          pred_point_id is int.

                              For a classification model with output shape
                              (classes,), returns a dictionary as follows:
                                  * Dict Key: an class value from classes.
                                  * Dict Element: a torch tensor with shape:
                                          > (prediction_points, in_chunk,
                                          in_components) if pred_point_id is
                                          a tuple.
                                          > (in_chunk, in_components) if
                                          pred_point_id is int.




