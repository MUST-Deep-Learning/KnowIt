KnowIt.data.base_dataset
========================

.. py:module:: KnowIt.data.base_dataset

.. autoapi-nested-parse::

   -----------
   BaseDataset
   -----------

   The ``BaseDataset`` represents a dataset that only contains raw features
   over time (i.e. components) in a known format.
   These features do not contain duplicates, and are ordered equidistantly according to a
   specific time delta. They are seperated by "instance" and by "slice". See below.

   An instance is a potential occurrences of a phenomenon measured across time,
   assumed to be independent of other potential occurrences. For example, if two subjects
   are measured / observed at the same time. These two subjects should be stored as separate instances.
   The main practical distinction is that no duplicate time steps are allowed within an instance,
   but they are allowed across instances. If no instances are defined, all slices are stored in
   one "super instance".

   A slice is just a contiguous block of time steps, within a single instance,
   with an exact time delta between each time step.
   An instance, therefore, consists of a variable number of slices.

   ------------
   Date storage
   ------------

   The `BaseDataset` is stored on disk as a partitioned parquet dataset (package)
   along with a pickled dictionary of metadata. The stored metadata includes the name
   and structure of the dataset along with other characteristics like the
   time delta.

   Along with the metadata, the data package itself is stored as a directory containing
   a set of instances and underlying slices.

   - <dataset name>
       - <instance=0>
           - <slice=0>
               - file.parquet
           - ...
           - <slice=M>
               - file.parquet
       - ...
       - <instance=N>
           - <slice=0>
               - file.parquet
           - ...
           - <slice=M>
               - file.parquet

   Each parquet file represents a dataframe for which the rows are:
       - Time indexed
       - Contiguous
       - Chronologically ordered
       - Without duplicate entries.
   The columns in the dataframe are:
       - A set of columns representing the components, in the order that they are defined in the metadata.
       - A column indicating the instance of the current time step.
       - A column indicating the slice of the current time step.

   ---------------
   Dataset options
   ---------------

   ``BaseDataset`` is instantiated with a path to the metadata (i.e. meta_path) and a path to the
   data package (i.e. package_path).

   To construct the above-mentioned variables, the ``BaseDataset.from_path`` and ``BaseDataset.from_df``,
   of which the former is a wrapper for the latter, can be used to import external data (in Dataframe format)
   and package it into the expected structure. A dataframe needs to be provided that has the minimum required
   metadata in its "attrs" attribute.
   The BaseDataset module uses the ``RawDataConverter`` module to convert this dataframe
   into a known structure. See that module for more details.



Classes
-------

.. autoapisummary::

   KnowIt.data.base_dataset.BaseDataset
   KnowIt.data.base_dataset.DataExtractor


Module Contents
---------------

.. py:class:: BaseDataset(meta_path, package_path)

   This is the BaseDataset class. It is the parent class of all other dataset classes
   and serves to load, clean, compile, and store raw data (with critical metadata).
   It does not carry any concept of models or training, only information related to the data.

   :Parameters: * **meta_path** (:py:class:`str`) -- The path to the desired dataset metadata. The path should point to a pickle file.
                * **package_path** (:py:class:`str`) -- The path to the desired dataset package. The path should point to a directory containing the
                  partitioned parquet.

   :ivar meta_path: The path to the metadata.
   :vartype meta_path: :py:class:`str`
   :ivar package_path: The path to the data package.
   :vartype package_path: :py:class:`str`
   :ivar name: The unique identifier used by KnowIt to refer to the specific dataset.
   :vartype name: :py:class:`str`
   :ivar components: A list of components that were measured across time.
                     It also defines the order of features in the stored data structure.
   :vartype components: :py:class:`list`
   :ivar instance_names: A dictionary containing the original instance names.
                         The key is an integer identifier and the value is the original name for the instance at import time.
   :vartype instance_names: :py:class:`dict[int`, :py:class:`Any]`
   :ivar data_structure: A dictionary containing the data structure.
                         Each key indicates an instance,
                         each value indicates a dictionary of slices (for which the values are the number of prediction points in the slice).
   :vartype data_structure: :py:class:`dict[int`, :py:class:`dict]`
   :ivar time_delta: The specific time delta between time steps.
   :vartype time_delta: :py:class:`timedelta`
   :ivar base_nan_filler: Identifies the method used to fill NaNs, if applicable, at import time.
   :vartype base_nan_filler: :py:class:`str | None`, *default* :py:obj:`None`
   :ivar nan_filled_components: A list of components that were nan-filled, if applicable, at import time.

   :vartype nan_filled_components: :py:class:`list | None`, *default* :py:obj:`None`


   .. py:method:: get_extractor()

      Return a DataExtractor object corresponding to the current BaseDataset.

      This object can be used to extract particular portions of the BaseDataset from disk.

      :returns: The DataExtractor object.
      :rtype: :py:class:`DataExtractor`



   .. py:method:: from_raw(exp_output_dir, raw_data, safe_mode, base_nan_filler, nan_filled_components, meta)
      :classmethod:


      Instantiate a BaseDataset object from raw data, either a file path or a DataFrame.

      :Parameters: * **exp_output_dir** (:py:class:`str`) -- The directory path for experiment output.
                   * **raw_data** (:py:class:`str | DataFrame`) -- Either a file path to the raw data or a pandas DataFrame containing the raw data.
                   * **safe_mode** (:py:class:`bool`) -- A flag indicating whether to operate in safe mode.
                   * **base_nan_filler** (:py:class:`str | None`) -- The method used to fill NaNs in the base dataset.
                   * **nan_filled_components** (:py:class:`list | None`) -- A list of components in the dataset that should have NaNs filled.
                   * **meta** (:py:class:`dict | None`) -- A dictionary containing the required metadata or None.
                     If None, metadata should be provided in file at path.

      :returns: An instance of the BaseDataset class initialized with the provided raw data.
      :rtype: :py:class:`data.BaseDataset`

      .. rubric:: Notes

      - If `raw_data` is a string, it is treated as a file path and processed via `BaseDataset.from_path`.
      - If `raw_data` is a pandas DataFrame, it is processed via `BaseDataset.from_df`.
      - The method delegates to appropriate class methods based on the type of `raw_data`.



   .. py:method:: from_path(exp_output_dir, path, safe_mode, base_nan_filler, nan_filled_components, meta)
      :classmethod:


      Instantiate a BaseDataset object by first creating the dataset from a given path
      to a file containing a dataframe with raw data.

      This method loads data from the specified path (to a .pickle),
      then creates and returns an instance of the BaseDataset class using that data.

      :Parameters: * **exp_output_dir** (:py:class:`str`) -- The directory path for experiment output.
                   * **path** (:py:class:`str`) -- The file path to the raw data file containing a dataframe.
                   * **safe_mode** (:py:class:`bool`) -- A flag indicating whether to operate in safe mode.
                   * **base_nan_filler** (:py:class:`str | None`) -- The method used to fill NaNs in the base dataset.
                   * **nan_filled_components** (:py:class:`list | None`) -- A list of components in the dataset that should have NaNs filled.
                   * **meta** (:py:class:`dict | None`) -- A dictionary containing the required metadata or None.
                     If None, metadata should be provided in file at path.

      :returns: An instance of the BaseDataset class, initialized with the loaded data and specified parameters.
      :rtype: :py:class:`BaseDataset`



   .. py:method:: from_df(df, exp_output_dir, safe_mode, base_nan_filler, nan_filled_components, meta)
      :classmethod:


      Instantiate a BaseDataset object by first creating the dataset option from a given dataframe with raw data.

      This method converts the provided dataframe into the necessary format and saves it,
      then creates and returns an instance of the BaseDataset class using that data.

      :Parameters: * **df** (:py:class:`DataFrame`) -- The dataframe containing raw data to be converted.
                   * **exp_output_dir** (:py:class:`str`) -- The directory path for experiment output.
                   * **safe_mode** (:py:class:`bool`) -- A flag indicating whether to operate in safe mode.
                   * **base_nan_filler** (:py:class:`str | None`) -- The method used to fill NaNs in the base dataset.
                   * **nan_filled_components** (:py:class:`list | None`) -- A list of components in the dataset that should have NaNs filled.
                   * **meta** (:py:class:`dict | None`) -- A dictionary containing the required metadata or None.
                     If None, expected to be in df.attrs.

      :returns: An instance of the BaseDataset class, initialized with the processed data and specified parameters.
      :rtype: :py:class:`BaseDataset`

      .. rubric:: Notes

      See ``KnowIt.raw_data_conversion`` for details on base_nan_filler.



.. py:class:: DataExtractor(package_path, components, instance_names, data_structure, engine = 'pyarrow', cache_size = 100)

   A class for efficiently extracting specific portions of a partitioned Parquet dataset from disk.
   Uses an LRU cache to optimize repeated reads.

   :Parameters: * **package_path** (:py:class:`str`) -- Path to the directory containing the partitioned Parquet dataset.
                * **components** (:py:class:`list`) -- List of column names to be read from the dataset.
                * **instance_names** (:py:class:`dict`) -- Dictionary mapping instance identifiers to human-readable names (for reference).
                * **data_structure** (:py:class:`dict`) -- Dictionary describing the dataset's structure (e.g., metadata about partitions).
                * **engine** (:py:class:`str`, *default* ``"pyarrow"``) -- Parquet reading engine to use ('pyarrow' or 'fastparquet').
                * **cache_size** (:py:class:`int`, *default* ``100``) -- Maximum number of recently read partitions to store in the cache.


   .. py:method:: instance(i)

      Retrieves all data for a specific instance.

      :Parameters: **i** (:py:class:`int` or :py:class:`str`) -- The instance identifier.

      :returns: The dataset subset corresponding to the given instance.
      :rtype: :py:class:`pd.DataFrame`



   .. py:method:: slice(i, s)

      Retrieves data for a specific instance and slice.

      :Parameters: * **i** (:py:class:`int` or :py:class:`str`) -- The instance identifier.
                   * **s** (:py:class:`int`) -- The slice identifier.

      :returns: The dataset subset corresponding to the given instance and slice.
      :rtype: :py:class:`pd.DataFrame`



   .. py:method:: time_step(i, s, t)

      Retrieves a single time step from a given instance and slice.

      :Parameters: * **i** (:py:class:`int` or :py:class:`str`) -- The instance identifier.
                   * **s** (:py:class:`int`) -- The slice identifier.
                   * **t** (:py:class:`int`) -- The time step index.

      :returns: A row of the dataset corresponding to the given instance, slice, and time step.
      :rtype: :py:class:`pd.Series`



   .. py:method:: time_block(i, s, block)

      Retrieves a block of time steps from a given instance and slice.

      :Parameters: * **i** (:py:class:`int` or :py:class:`str`) -- The instance identifier.
                   * **s** (:py:class:`int`) -- The slice identifier.
                   * **block** (:py:class:`tuple` of :py:class:`(int`, :py:class:`int)`) -- A tuple defining the start and end indices for the time step range.

      :returns: A subset of the dataset containing the requested range of time steps.
      :rtype: :py:class:`pd.DataFrame`



